
# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'sandp500:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1908%2F17155%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240502%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240502T090710Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7d6f507e96a1c881d0bbf2b2f9cc6128c1ef5807d484558ca3ae56aeb403d1b47abd2d4801a9d44e5a62e934afa1eac294284041a8f0594d1e299b087a8d3376bbbb03acb3b793e042305dffb696ee96fd566c2026b7c5b63b86c19e4b0067888009f38e3c463612f43783e8138c8f5f19620c8195b75155509c11e9c5e7487bb1b6526f07412a1d35f2d4ef07bae335d6c7882f422cab52e99ba5cc67761fbf7afd4a731931fadf5914d53adadf27f8b496d12e7a57acb3a1accffaea707beac61083e36697ca28859611c85a3f591cd9743e9239f3c3a32a063f25177deb13e854656729efaa990965f27e4bbbdca91fa583db37776a8201cf29b37531b692,amzn-dpz-btc-ntfx-adjusted-may-2013may2019:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F195545%2F433077%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240502%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240502T090710Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3254fdaa94515a2a0cb89e2781e85ce27186253030abe87e6c0488a7c93bfc7a8bffdd96ab6b407d88fa6308cd39998092c070ce9e0c22dd930885524d2e49f3fe267d1670680b060f1c5aafee966ed94138045268d6b303adecb43cae86e681fe3054d57133a0b50ec6239ec9a32831690bf8ac995a4a0cae34439e68f7caca1b995d0c65e91163e58595b95167ba4e8af7059c6a724865e7d65e96c676562f05936c42b8a4c61ca5a9e1b3103536eb11ede4d43d472acba4cae751ac62400b97fdb0b17ec2f32e7ccfe134da574ab1d338c6dcde486eaf3804d75ceac4159ff26cfd9139b0ed80d1897d8b9f869a0ed555db9373fa173021f4bebe3b189502,apple-aapl-historical-stock-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F533900%2F976925%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240502%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240502T090710Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D777b17aba16c087248ebd7877422960d2be9054d1dd53a2f78f2c99ec74886a793bb1c2bcade8eddc01865cd356aa734f98a83e9464c43dc7e254145c070355a91d98774e9812ae7faf90426f15b75f93f563702bdb4d45dc2c58844d032808178c384c185b714f247233f3196201b59500db1aa95b960f7d87c57ed3b0762d19f197f0a576e7533bd27b2b4bf05528269ae8973b7f55e139272500528900d80ac33a752aca90bf23b3a3aefb16e66c1e57bf7ff7feb018988db47ae027665ee42b1a1e6f2b1f4dd204a0f83a9a4b6479f295f26d211d8edd72f148d6968f3062c78999ded97b41860f51f9514e9453aa65bb64ad396682f070daf8a46ffbd14,tesla-stock-price:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2076127%2F7417167%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240502%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240502T090710Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2194159b1c8c5de38b8f9aa2839faf6bb528122938d80d039cbd15df3adb441f2eb485626d7af7c7215fa4fb084e337f4565957e347db2827453f9de71967c8adbc9537c0241b363ae4fca130881cd0b1dbcd0ec262cf3286087f0af4d2547e0cfe8b776d469d16b9e0b14871f9d854301a666d9d357734dd9530db71523d37ce4aca877fe1bfd7173981e1318886011e4da1361ee1546dec3cfd1311927f0ea2b06338eb2e93446a5560303d8fc6180f5a67423a36a66d6d79e0385e54216789fd1a81fc7455b0835041d855616440a76c1fd607321747888f9c466804ab9c74c2f66e09b046d08c83ae2d076c146457490ecb57cfafcc1735212b3cd91441b'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')


pip install yfinance


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
sns.set_style('whitegrid')
plt.style.use('https://github.com/dhaitz/matplotlib-stylesheets/raw/master/pitayasmoothie-dark.mplstyle')
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import LSTM, Dense
from datetime import datetime, timedelta
import math

import yfinance as yf

yf.pdr_override()

# For this analysis, we will focus on technology stocks and innovative growth stocks
stocks_list = ['AAPL', 'GOOG', 'TSLA', 'NVDA']

end = datetime.now()
start = datetime(end.year - 2, end.month, end.day)

for stock in stocks_list:
    globals()[stock] = yf.download(stock, start, end)
    

company_list = [AAPL, GOOG, TSLA, NVDA]
company_name = ["APPLE", "GOOGLE", "TESLA", "NVIDA"]

for company, com_name in zip(company_list, company_name):
    company["company_name"] = com_name
    
df = pd.concat(company_list, axis=0)
df.tail(10)



# Summary statistics
AAPL.describe()


# First 5 rows
AAPL.head(5)



df.isna().sum()

# Let's see a historical view of the closing price

plt.figure(figsize=(15, 10))
plt.subplots_adjust(top=1.25, bottom=1.2)

for i, company in enumerate(company_list, 1):
    plt.subplot(2, 2, i)
    company['Adj Close'].plot()
    plt.ylabel('Adj Close')
    plt.xlabel(None)
    plt.title(f"Closing Price of {stocks_list[i - 1]}")
    plt.grid(True)
    
plt.tight_layout() # Ensures proper spacing between subplots


# Plotting the closing price for each week

plt.figure(figsize=(15, 10))
plt.subplots_adjust(top=1.25, bottom=1.2)

for i, company in enumerate(company_list, 1):
    plt.subplot(2, 2, i)
    weekly_data = company['Adj Close'].resample('W').mean() # Resample the data to get weekly averages
    weekly_data.plot(marker='o', linestyle='-')
    plt.title(f'Monthly Closing Price for {stocks_list[i - 1]}')
    plt.xlabel(None)
    plt.ylabel('Closing Price (USD)')
    plt.grid(True)

plt.tight_layout() 



# Plotting Candlestick chart for Apple stock price

fig = go.Figure(data=[go.Candlestick(x=AAPL.index,
                open=AAPL['Open'],
                high=AAPL['High'],
                low=AAPL['Low'],
                close=AAPL['Close'])])

fig.update_layout(title='Apple Stock Price Candlestick Chart',
                  xaxis_title='Date',
                  yaxis_title='Stock Price (USD)')

fig.update_layout(template='plotly_dark')

fig.show()



# calculating and plotting MA for each stock
plt.figure(figsize=(15, 10))
plt.subplots_adjust(top=1.25, bottom=1.2)

for i, company in enumerate(company_list, 1):
    plt.subplot(2, 2, i)
    
    company['MA50'] = company['Close'].rolling(window=50).mean()
    company['MA100'] = company['Close'].rolling(window=100).mean()
    
    plt.plot(company['Close'], label='Tesla Stock Price')
    plt.plot(company['MA50'], label='50-day Moving Average')
    plt.plot(company['MA100'], label='100-day Moving Average')
    plt.title(f'{stocks_list[i - 1]} Stock Price with Moving Averages')
    plt.xlabel(None)
    plt.ylabel('Stock Price (USD)')
    plt.legend()
    plt.grid(True)

plt.tight_layout()
plt.show()




import plotly.express as px

AAPL['MA50'] = AAPL['Close'].rolling(window=50).mean()
AAPL['MA200'] = AAPL['Close'].rolling(window=200).mean()

# Create a Plotly line plot for AAPL
fig = px.line(AAPL, x=NVDA.index, y=['Close', 'MA50', 'MA200'], title='AAPL Stock Price with Moving Averages')

fig.update_layout(template='plotly_dark')

fig.show()


# calculating and plotting RSI for each stock

plt.figure(figsize=(15, 24))
plt.subplots_adjust(top=1.25, bottom=1.2)

for i, company in enumerate(company_list, 1):
    plt.subplot(4, 1, i)
    
    # Calculate daily price change
    company['Daily Change'] = company['Close'].diff()

    # the lookback period for RSI
    period = 14    # a lookback period of 14 is a common choice for calculating the RSI

    # Calculate the average gain and average loss
    company['Gain'] = company['Daily Change'].apply(lambda x: x if x > 0 else 0)
    company['Loss'] = company['Daily Change'].apply(lambda x: -x if x< 0 else 0)
    company['Average Gain'] = company['Gain'].rolling(window=period).mean()
    company['Average Loss'] = company['Loss'].rolling(window=period).mean()

    # Calculate the relative strength  (RS)
    company['RS'] = company['Average Gain'] / company['Average Loss']

    # Calculate the RSI
    company['RSI'] = 100 - (100 / (1 + company['RS']))

    # Plotting the RSI
    plt.plot(company.index, company['RSI'], label=f'{stocks_list[i - 1]} RSI', color='c')
    plt.axhline(y=70, color='r', linestyle='dashdot')
    plt.axhline(y=30, color='g', linestyle='dashdot')
    plt.title(f'{stocks_list[i - 1]} Stock RSI ')
    plt.xlabel(None)
    plt.ylabel('RSI')

plt.tight_layout()
plt.show()



#  Plotting a short-term volatility chart for each stock

plt.figure(figsize=(15, 10))
plt.subplots_adjust(top=1.25, bottom=1.2)

for i, company in enumerate(company_list, 1):
    plt.subplot(2, 2, i)
    company['Volatility'] = company['Close'].pct_change().rolling(window=20).std()
    plt.plot(company['Volatility'], label='Volatility')
    plt.title(f'Volatility of {stocks_list[i - 1]} Stock Price')
    plt.xlabel(None)
    plt.ylabel('Volatility')
    plt.grid(True)
    plt.legend()


plt.tight_layout() 
plt.show()

# Download S&P 500 data
sp500_data = yf.download('^GSPC', start=start, end=end)

# Create a DataFrame to store correlation values
correlation_data = []

for i, company in enumerate(company_list, 1):
    correlation = company['Close'].corr(sp500_data['Close'])
    correlation_data.append({'Company': stocks_list[i - 1], 'Correlation': correlation})
    print(f"'Company : {stocks_list[i - 1]} Correlation: {correlation}")
    


correlation_df = pd.DataFrame(correlation_data)
heatmap_data = correlation_df.pivot_table(index='Company', columns='Company', values='Correlation', fill_value=0)

plt.figure(figsize=(10, 8))
sns.heatmap(heatmap_data, cmap='Blues_r', annot=True, fmt=".2f", linewidths=.5)
plt.title('Correlation Heatmap with S&P 500')
plt.show()

sharpe_ratios = []
stock_names = []

# Calculate Sharpe Ratio for each company
for i, company in enumerate(company_list, 1):
    company['Daily Returns'] = company['Close'].pct_change()
    sharpe_ratio = np.sqrt(252) * (company['Daily Returns'].mean() / company['Daily Returns'].std())
    print(f"Sharpe Ratio for {stocks_list[i - 1]}: {sharpe_ratio}")
    sharpe_ratios.append(sharpe_ratio)
    stock_names.append(stocks_list[i - 1])


plt.barh(stock_names, sharpe_ratios, color='c') 
plt.xlabel('Stocks')
plt.ylabel('Sharpe Ratio')
plt.title('Sharpe Ratio for Each Stock')
plt.show()


# create a new data frame with only 'Close column'
apple_data = AAPL.filter(['Close'])
data = apple_data.values




scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)




# Splitting the scaled data into training and testing sets
training_data_len = int(np.ceil(len(scaled_data) * .8))
train_data = scaled_data[0:int(training_data_len), :]

#Split the data into x_train, y_train datasets
x_train, y_train = [], []
for i in range(60, len(train_data)):
    x_train.append(train_data[i - 60:i, 0])
    y_train.append(train_data[i,0])
    
#convert the x_train and y_train to numppy array and reshape the data
x_train, y_train = np.array(x_train), np.array(y_train)
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
x_train.shape



# Building the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(units=50, return_sequences=True))
model.add(LSTM(units=25))
model.add(Dense(units=1))
model.summary()



# Compiling and training the LSTM model
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(x_train, y_train, batch_size=1, epochs=20)


# Preparing test data and making predictions
test_data = scaled_data[training_data_len - 60:, :]
x_test = []
y_test = data[training_data_len:,:]

for i in range(60, len(test_data)):
    x_test.append(test_data[i -60:i, 0])


# convert the data to a numpy array and reshape the data
x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))


predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)


# Evaluating model performance using Root Mean Squared Error (RMSE)
rmse = np.sqrt(mean_squared_error(y_test, predictions))
print(f'Root Mean Squared Error: {rmse}')



# Plotting the predicted stock prices against actual prices
dataset = apple_data.filter(['Close'])
train = dataset[:training_data_len]
test = dataset[training_data_len:]
test['Predictions'] = predictions
# Visualize the data
plt.figure(figsize=(16,6))
plt.title('Model')
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Price USD ($)', fontsize=18)
plt.plot(train['Close'])
plt.plot(test[['Close', 'Predictions']])
plt.legend(['Train', 'Test', 'Predictions'], loc='lower right')
plt.show()




#show the test and predicted price
test


actual_values = y_test 
predicted_values = predictions

plt.figure(figsize=(10, 6))

# Scatter plot of predicted vs. actual values
plt.subplot(2, 2, 1)
plt.scatter(predicted_values, actual_values, alpha=0.7)
plt.title('Predicted vs. Actual Values')
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')





# Calculate residuals
residuals = actual_values - predicted_values
plt.figure(figsize=(10, 6))

# Residuals vs. Predicted Values
plt.subplot(2, 2, 2)
plt.scatter(predicted_values, residuals, alpha=0.7)
plt.axhline(y=0, color='red', linestyle='--')
plt.title('Residuals vs. Predicted Values')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')




plt.figure(figsize=(10, 6))

# Residuals Histogram
plt.subplot(2, 2, 3)
plt.hist(residuals, bins=20, edgecolor='black')
plt.title('Residuals Histogram')
plt.xlabel('Residuals')
plt.ylabel('Frequency')



